Time-Continuous Neural Networks provide an effective framework for the modelling of dynamical systems \cite{Chen2018NeuralOD} and are natural candidates for continuous-control tasks. They are closely related to the dynamics of non-spiking neurons, which gives further justification to investigate their use in control \cite{Lechner2020NeuralCP}. \\

In the following discussion, we only worry about time-independent (sometimes also refered to as autonomous) systems, as those are more relevant for control, but most of those approaches generalize well to time-dependent systems as well. Time-Continuous Neural Networks model dynamical systems model the evolution of the hidden states (which we denote as $\bm{x}_t$ at a given time $t$) of a neural network by equations of the form: 

\begin{align}
    \frac{\partial \bm{x}_t}{\partial t} = D(\bm{x}_t, \bm{I}_t, \theta, A).
\end{align}
 
 Where $D$ denotes some kind of model function that estimates the time-derivative of $\bm{x}_t$. $D$ is a function of $\bm{x}_t$, which denotes the hidden state of the neuron, $\bm{I}_t$ which denotes the inputs of the neuron, a fixed parameter vector $A$ and a learnable parameter vector $\theta$. Updates of the (hidden) state $\bm{x}_t$ are the computed using some ODE solver which integrates $\frac{\partial \bm{x}_t}{\partial t}$ over some time-step $\Delta t$ to compute $\bm{x}_{t+\Delta t} = \int_t^{t+\Delta t} \frac{\partial \bm{x}_t}{\partial t} + \bm{x}_t$. \\
 
 One early contribution to Time-Continuous Neural Networks is CT-RNNs \cite{Funahashi1993ApproximationOD}, which pick $D$ as: 

\begin{align}
    D(\bm{x}_t, \bm{I}_t, \theta, A) = -\frac{\bm{x}_t}{\tau} + f(\bm{x}_t, \bm{I}_t, \theta, A).
\end{align}

where $\tau$ is a fixed time constant (according to our formalism it is an element of the vector $A$) and $f$ a non-linear activation function. In their original paper, Funahashi and Nakamura propose to use $f = \sum_{j=1}^m w{i,j} \cdot \sigma\left( x_{i,t} \right) + I_i (t)$, where the weights $w{i,j}$ are elements of the vector $\theta$. \\

More recently, one suggested implementation that seems to give better performance is given by Liquid Time-Constant networks (LTCs) \cite{Hasani2021LiquidTN}. In that case the activation $f$ affects both the time-constant and the non-linearity (hence the "liquid" time-constant), this approach corresponds to the following time-derivative model:

\begin{align}
    D(\bm{x}_t, \bm{I}_t, \theta, A) = - \left[ \frac{1}{\tau} + f(\bm{x}_t, \bm{I}_t, \theta, A) \right] \bm{x}_t \nonumber \\ + f(\bm{x}_t, \bm{I}_t, \theta, A).
\end{align}

In practice, Hasani and Lechner propose to use the following activation function: $f(\bm{x}_t, \bm{I}_t, \theta, A) = \tanh (w_r \bm{x} + w \bm{I} + \mu)$, which is loosely connected to synaptic dynamics in biology \cite{Lechner2020NeuralCP}.

\begin{table}[h!]
\centering
\caption{Time-Continuous Neural Network Classes}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{l|c|c}
\textbf{ } & \textbf{Hidden state equation} & \textbf{ Recurrent? } \\ 
\hline
CT-RNN & $ \frac{\partial \bm{x}_t}{\partial t} = -\frac{\bm{x}_t}{\tau} + f(\bm{x}_t, \bm{I}_t, \theta, A)$ & yes \\
LTC & $ \frac{\partial \bm{x}_t}{\partial t} = - \left[ \frac{1}{\tau} + f(\bm{x}_t, \bm{I}_t, \theta, A) \right] \bm{x}_t + f(\bm{x}_t, \bm{I}_t, \theta, A)$ & yes \\
Neural-ODE &  $ \frac{\partial \bm{x}_t}{\partial t} = f(\bm{x}_t, \bm{I}_t, \theta, A)$
\end{tabular}%
}
\end{table}

\subsubsection{Key questions to answer about TCNs}
\begin{itemize}
    \item Network properties
    \begin{itemize}
        \item Why use CT-RNNs instead of RNNs
        \item Why use LTCs instead of CT-RNNs
        \item What is the difference with Neural ODEs
    \end{itemize}
    \item Forward passes
    \begin{itemize}
        \item What solver to used for the ODE step
    \end{itemize}
    \item Training
    \begin{itemize}
        \item How does BPTT works?
    \end{itemize}
\end{itemize}